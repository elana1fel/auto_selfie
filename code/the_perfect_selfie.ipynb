{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial import distance as dist\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import imutils\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selfie Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_img(frame):\n",
    "    '''\n",
    "    This functions gets an image and does the following:\n",
    "        1. resizes the image\n",
    "        2. changes the image to gray-scale\n",
    "\n",
    "    Input:\n",
    "        frame   numpy array\n",
    "    '''\n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    return gray, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_regular_selfie(frame, total, output_folder):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    img_name = os.path.join(output_folder, \"selfie_frame_{}.png\".format(total))\n",
    "\n",
    "    cv2.imwrite(img_name, frame)\n",
    "    print(\"{} written!\".format(img_name))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouth_aspect_ratio(mouth):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    A = dist.euclidean(mouth[3], mouth[9])\n",
    "    B = dist.euclidean(mouth[2], mouth[10])\n",
    "    C = dist.euclidean(mouth[4], mouth[8])\n",
    "    avg = (A + B + C) / 3\n",
    "    D = dist.euclidean(mouth[0], mouth[6])\n",
    "    mar = avg/D\n",
    "    return mar #return the mouth aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "\n",
    "    # return the eye aspect ratio\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    print(\"Initializing model\")\n",
    "    shape_predictor= \"dat_files/shape_predictor_68_face_landmarks.dat\" #dace_landmark\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(shape_predictor)\n",
    "    return detector, predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(np_img, detector, predictor):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    faces = []\n",
    "    mouth_start, mouth_end = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "    l_eye_start, l_eye_end = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "    r_eye_start, r_eye_end = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "    rects = detector(np_img, 0)\n",
    "    for rect in rects:\n",
    "        shape = predictor(np_img, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        mouth = shape[mouth_start:mouth_end]\n",
    "        l_eye = shape[l_eye_start:l_eye_end]\n",
    "        r_eye = shape[r_eye_start:r_eye_end]\n",
    "        mar = mouth_aspect_ratio(mouth)\n",
    "        l_ear = eye_aspect_ratio(l_eye)\n",
    "        r_ear = eye_aspect_ratio(r_eye)\n",
    "\n",
    "        faces.append({'mar': mar,\n",
    "                      'mouth_hull' : cv2.convexHull(mouth),\n",
    "                      'l_ear' : l_ear, \n",
    "                      'l_eye_hull' : cv2.convexHull(l_eye),\n",
    "                      'r_ear' : r_ear,\n",
    "                      'r_eye_hull' : cv2.convexHull(r_eye)})\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similiarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imgs(imgs_list, imgs_name_list=None, params=None, save=False):\n",
    "    '''\n",
    "    This func gets images and plots them side by side\n",
    "    Input:\n",
    "        imgs_list       np.array list       list of imgs to plot\n",
    "        imgs_name_list  list of str         list of imgs name\n",
    "        params          str                 str to describe running params to be used as title    \n",
    "    '''\n",
    "    imgs_num = len(imgs_list)\n",
    "    if imgs_num == 4:\n",
    "        fig, axarr = plt.subplots(2, 2)\n",
    "        i_range = 2\n",
    "        j_range = 2\n",
    "    \n",
    "        counter = 0\n",
    "        for i in range(i_range):\n",
    "            for j in range(j_range):\n",
    "                axarr[i][j].imshow(imgs_list[counter], cmap='gray')\n",
    "                if imgs_name_list is not None:\n",
    "                    axarr[i][j].set_title(imgs_name_list[counter])\n",
    "                counter += 1\n",
    "\n",
    "    else:\n",
    "        fig, axarr = plt.subplots(1, imgs_num)\n",
    "        i_range = imgs_num\n",
    "\n",
    "        for i in range(i_range):\n",
    "            axarr[i].imshow(imgs_list[i], cmap='gray')\n",
    "            if imgs_name_list is not None:\n",
    "                axarr[i].set_title(imgs_name_list[i])\n",
    "\n",
    "    if params is not None:\n",
    "        fig.suptitle(params)\n",
    "\n",
    "    save =False\n",
    "    if save:\n",
    "        params = params.split('\\n')[0]\n",
    "        plt.savefig(\"plots/\" + params + \".png\")\n",
    "\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(img1, img2):\n",
    "    '''\n",
    "    This func cumputes Mean Squared Error between the two images\n",
    "\n",
    "    Input:\n",
    "        img1        np.array\n",
    "        img2        np.array\n",
    "          \n",
    "    Output:\n",
    "        err         float       diff between images          \n",
    "    '''\n",
    "\n",
    "    err = np.sum((img1 - img2) ** 2)\n",
    "    err /= float(img1.shape[0] * img2.shape[1])\n",
    "\t\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sim(img1, img2, method=None, debug=False):\n",
    "    '''\n",
    "    This func checks whether two images are similiar\n",
    "\n",
    "    Input:\n",
    "        img1        np.array\n",
    "        img2        np.array\n",
    "        method      str         method for similarity test. it can be MSE or ssim\n",
    "          \n",
    "    Output:\n",
    "        similarity  bool        whether two images are similar\n",
    "    '''\n",
    "    \n",
    "    ssim_sim = True\n",
    "    mse_sim = True\n",
    "\n",
    "    (score, diff) = compare_ssim(img1, img2, full=True)\n",
    "    if score < 0.75:\n",
    "        ssim_sim = False\n",
    "    err = mse(img1, img2)\n",
    "    if err > 50.0:\n",
    "        mse_sim = False\n",
    "\n",
    "    if debug:\n",
    "        img3 = img1 - img2 #diff in MSE\n",
    "        img4 = diff\n",
    "        show_imgs([img1, img2, img3, img4], params=f\"ssim score is: {score:.2f} and MSE err is: {err:.2f}\")\n",
    "\n",
    "    return np.logical_and(ssim_sim, mse_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartoonifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_mask(img, line_size, blur_value):\n",
    "  '''\n",
    "  This functions creates an edge mask for given image using canny and dilation\n",
    "\n",
    "  Input:\n",
    "      img       numpy array     given image to create its edge mask\n",
    "\n",
    "  Output:\n",
    "      edges     numpy array     the edge mask of the image, with dilation\n",
    "  '''\n",
    "\n",
    "\n",
    "  ##################### start part of try using canny #####################\n",
    "  '''\n",
    "  # sigma, L_th, H_th = 1, 0.05, 0.27\n",
    "  \n",
    "  # edges = canny.cannyEdges(gray, sigma, L_th, H_th)\n",
    "  \n",
    "  # edges = edges.astype(np.uint8)\n",
    "  # edges = np.logical_not(edges)\n",
    "  # edges = edges*255\n",
    "  \n",
    "  # edges = edges.astype(np.uint8)\n",
    "  '''\n",
    "  ##################### end part of try usin canny #####################\n",
    "\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  gray_blur = cv2.medianBlur(gray, blur_value)\n",
    "  edges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value)\n",
    "\n",
    "  return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_quantization(img, k=9):\n",
    "\n",
    "  '''\n",
    "  This functions reduce the number of colors to a given image\n",
    "\n",
    "  Input:\n",
    "      img       numpy array     image to reduce its colors\n",
    "      k         int             number of new different colors\n",
    "\n",
    "\n",
    "  Output:\n",
    "      result     numpy array     image recolored to k different colors\n",
    "  '''\n",
    "\n",
    "# Transform the image\n",
    "  data = np.float32(img).reshape((-1, 3))\n",
    "\n",
    "# Determine criteria\n",
    "  criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 0.001)\n",
    "\n",
    "# Implementing K-Means\n",
    "  ret, label, center = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "  center = np.uint8(center)\n",
    "  result = center[label.flatten()]\n",
    "  result = result.reshape(img.shape)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartoonify(img, total, output_folder):\n",
    "  '''\n",
    "  This functions make a cartoon out of a given image and saves the cartoon in a given path\n",
    "\n",
    "  Input:\n",
    "      img               numpy array       image to create is cartoon\n",
    "      total             int               counter of number of selfies - used as id\n",
    "      output_folder     string            path to save the selfies in\n",
    "\n",
    "  '''\n",
    "\n",
    "  line_size = 7\n",
    "  blur_value = 7\n",
    "\n",
    "  edges = edge_mask(img, line_size, blur_value)\n",
    "  img = color_quantization(img)\n",
    "\n",
    "  ##################### start part of try using canny #####################\n",
    "  '''\n",
    "  # edges = np.repeat(edges[:, :, np.newaxis], 3, axis=2)\n",
    "  # cartoon = np.bitwise_and(img, edges)\n",
    "  '''\n",
    "  ##################### end part of try using canny #####################\n",
    "\n",
    "  blurred = cv2.bilateralFilter(img, d=7, sigmaColor=200, sigmaSpace=200)\n",
    "  cartoon = cv2.bitwise_and(blurred, blurred, mask=edges)\n",
    "\n",
    "  img_name = os.path.join(output_folder, \"selfie_cartoon_{}.png\".format(total))\n",
    "\n",
    "  cv2.imwrite(img_name, cartoon)\n",
    "\n",
    "  print(\"{} written!\".format(img_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pencilifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pencilMe(img, total, output_folder):\n",
    "    '''\n",
    "    This functions make a pancil sketch out of a given image and saves the sketch in a given path.\n",
    "    this is done by:\n",
    "        - Converting an image into gray_scale image\n",
    "        - Inverting the image\n",
    "        - Smoothing the image\n",
    "        - Obtaining the final sketch\n",
    "\n",
    "    Input:\n",
    "        img               numpy array       image to create is cartoon\n",
    "        total             int               counter of number of selfies - used as id\n",
    "        output_folder     string            path to save the selfies in\n",
    "\n",
    "    '''\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_invert = cv2.bitwise_not(img_gray)\n",
    "    img_smoothing = cv2.GaussianBlur(img_invert, (21, 21), sigmaX=0, sigmaY=0)\n",
    "    final_img = cv2.divide(img_gray, 255 - img_smoothing, scale=256)\n",
    "\n",
    "    img_name = os.path.join(output_folder, \"selfie_pancil_{}.png\".format(total))\n",
    "\n",
    "    cv2.imwrite(img_name, final_img)\n",
    "    print(\"{} written!\".format(img_name))## pencilifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL UNITE - MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeSelfies(frame, gray, output_folder, cartoon, pencil, useCascade, useDlib, useBoth, eyes_cascade = None, smile_cascade= None, faces = None):\n",
    "    '''\n",
    "    This functions takes the selfie if conditions of found smile and two eyes is met. the function call the desired filter function if needed\n",
    "\n",
    "    Input:\n",
    "\n",
    "        frame               numpy array             the current observed frame\n",
    "        gray                numpy array             the current observed frame as a gray scale image\n",
    "        output_folder       string                  path to save the selfies in\n",
    "        cartoon             boolean                 if true - use this filter when taking selfie\n",
    "        pencil              boolean                 if true - use this filter when taking selfie\n",
    "        useCascade          boolean                 if true - look for features only using cascades\n",
    "        useDlib             boolean                 if true - look for features only using Dlib\n",
    "        useBoth             boolean                 if true - look for features using cascades and Dlib\n",
    "        eyes_cascade        numpy array             array of arrays of coordinates of found eyes on image by using haar cascade.\n",
    "        smile_cascade       numpy array             array of coordinates of found smile on image by using haar cascade.\n",
    "        faces               dict                    dict contains features found using Dlib\n",
    "\n",
    "    '''\n",
    "    global total, counter, last_taken_selfie\n",
    "\n",
    "    featuresDetected = False\n",
    "    detectCascade = ((eyes_cascade is not None) and (smile_cascade is not None ) and (len(eyes_cascade)%2 ==0) and (len(smile_cascade)>=1))\n",
    "    detectDlib = False\n",
    "    if faces:\n",
    "        for face in faces:\n",
    "            currentFaceDetectDlib = (face['mar'] <= .26 or face['mar'] > .32) and (face['l_ear'] > .25) and (face['r_ear'] > .25)\n",
    "            detectDlib = currentFaceDetectDlib or detectDlib\n",
    "\n",
    "    if useBoth and detectCascade and detectDlib:\n",
    "        featuresDetected = True\n",
    "\n",
    "    elif useCascade and detectCascade:\n",
    "        featuresDetected = True\n",
    "\n",
    "    elif useDlib and detectDlib:\n",
    "        featuresDetected = True\n",
    "\n",
    "    if featuresDetected:\n",
    "        counter += 1\n",
    "\n",
    "        # print(f\"counter is: {counter}\")\n",
    "        if counter >= 5:  # we need to check it\n",
    "            if last_taken_selfie is not None:\n",
    "                score = compare_sim(last_taken_selfie, gray)\n",
    "                # print(\"SSIM: {}\".format(score))\n",
    "                # check if there is a difference between current img to last taken selfie.\n",
    "                # if it is the same go back to while loop\n",
    "\n",
    "                if score:\n",
    "                    total += 1\n",
    "                    if cartoon:\n",
    "                        cartoonify(frame, total, output_folder)\n",
    "                    elif pencil:\n",
    "                        pencilMe(frame, total, output_folder)\n",
    "                    else:\n",
    "                        take_regular_selfie(frame, total, output_folder)\n",
    "                    last_taken_selfie = gray\n",
    "                    counter = 0\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                # first selfie\n",
    "\n",
    "                if cartoon:\n",
    "                    cartoonify(frame, total, output_folder)\n",
    "                elif pencil:\n",
    "                    pencilMe(frame, total, output_folder)\n",
    "                else:\n",
    "                    take_regular_selfie(frame, total, output_folder)\n",
    "\n",
    "                total += 1\n",
    "                last_taken_selfie = gray\n",
    "                counter = 0\n",
    "\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haarDetection(face_cascade, eye_cascade, smile_cascade, gray, img):\n",
    "    '''\n",
    "    This functions detect the face, eyes and smile in a given gray image and draw the detection on the colored image - all using haar cascades\n",
    "\n",
    "    Input:\n",
    "        face_cascade        Cascade Classifier      classifier that is used to detect faces in a given image\n",
    "        eye_cascade         Cascade Classifier      classifier that is used to detect eyes in a given image\n",
    "        smile_cascade       Cascade Classifier      classifier that is used to detect smile in a given image\n",
    "        gray                numpy array             the current observed frame as a gray scale image\n",
    "        img                 numpy array             the current observed frame\n",
    "\n",
    "\n",
    "    Output:\n",
    "        img                 numpy array             the current observed frame with the rectangles of the detect face, eyes and smile\n",
    "        eyes                numpy array             array of arrays of coordinates of found eyes on image.\n",
    "        smile               numpy array             array of coordinates of found smile on image.\n",
    "\n",
    "    '''\n",
    "    eyes = None\n",
    "    smile = None\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x_face, y_face, w_face, h_face) in faces:\n",
    "        cv2.rectangle(img, (x_face, y_face), (x_face+w_face, y_face+h_face), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y_face:y_face + h_face, x_face:x_face + w_face]\n",
    "        roi_color = img[y_face:y_face + h_face, x_face:x_face + w_face]\n",
    "\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=1.03, minNeighbors=40, minSize=(30,30))\n",
    "        for (x_eye, y_eye, w_eye, h_eye) in eyes:\n",
    "            cv2.rectangle(roi_color, (x_eye, y_eye), (x_eye + w_eye, y_eye + h_eye), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        # add from eyes pattern\n",
    "        smile = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.2, minNeighbors=40, minSize=(30,30))\n",
    "        for (x_smile, y_smile, w_smile, h_smile) in smile:\n",
    "            cv2.rectangle(roi_color, (x_smile, y_smile), (x_smile + w_smile, y_smile + h_smile), (0, 255, 0), 2)\n",
    "\n",
    "    return img, eyes, smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dlibDetection(frame, detector, predictor, show_stats, draw_contours):\n",
    "    '''\n",
    "    This functions detect the face, eyes and smile in a given image and draw the detection of the features - using Dlib\n",
    "\n",
    "    Input:\n",
    "        frame               numpy array      classifier that is used to detect faces in a given image\n",
    "        detector\n",
    "        predictor\n",
    "        show_stats          boolean             indicates if show stats of features on image\n",
    "        draw_contours       boolean             indicates if show contours of features on image\n",
    "\n",
    "\n",
    "    Output:\n",
    "        resized_frame       numpy array             the frame resized\n",
    "        faces               dict                    dict contains features found using Dlib\n",
    "\n",
    "    '''\n",
    "    gray_img, resized_frame = edit_img(frame)\n",
    "    faces = detect_face(gray_img, detector, predictor)\n",
    "\n",
    "    i = 0  # for putText\n",
    "    for face in faces:\n",
    "        if draw_contours:\n",
    "            for face_part in ['mouth_hull', 'l_eye_hull', 'r_eye_hull']:\n",
    "                cv2.drawContours(resized_frame, [face[face_part]], -1, (0, 255, 0), 1)\n",
    "\n",
    "        if show_stats:\n",
    "            y0, dy = 30, 30\n",
    "            for ar in ['mar', 'l_ear', 'r_ear']:\n",
    "                y = y0 + i * dy\n",
    "                cv2.putText(resized_frame, f\"{ar}: {face[ar]:.5f}\", (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                            (0, 0, 255), 2)\n",
    "                i += 1\n",
    "            cv2.putText(resized_frame, f\"{'mar'}: {face['mar']}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                        (0, 0, 255), 2)\n",
    "    return resized_frame, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(useCascade, useDlib, useBoth, face_cascade=None, eye_cascade=None, smile_cascade=None, cartoon=False, pencil=False):\n",
    "    '''\n",
    "    This functions is the main function of the selfies.\n",
    "    it reads the frames from the camera and take the selfie with or without filter.\n",
    "    the function also lets the user can change the filter selection by clicking on the relevant letters.\n",
    "\n",
    "    Input:\n",
    "        useCascade          boolean                 if true - look for features only using cascades\n",
    "        useDlib             boolean                 if true - look for features only using Dlib\n",
    "        useBoth             boolean                 if true - look for features using cascades and Dlib\n",
    "        face_cascade        numpy array             array of coordinates of found face on image by using haar cascade.\n",
    "        eyes_cascade        numpy array             array of arrays of coordinates of found eyes on image by using haar cascade.\n",
    "        smile_cascade       numpy array             array of coordinates of found smile on image by using haar cascade.\n",
    "        cartoon             boolean                 if true - use this filter when taking selfie\n",
    "        pencil              boolean                 if true - use this filter when taking selfie\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    print(\"for regular selfies press 'n'\\n\"\n",
    "          \"for cartoon selfies press 'c'\\n\"\n",
    "          \"for pencil selfies press 'p'\\n\")\n",
    "\n",
    "    output_folder = 'selfies_' + time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "\n",
    "    print(\"starting looking for perfect selfie mode\")\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    final, eye, smile = None, None, None\n",
    "    faces = None\n",
    "\n",
    "    detector, predictor = init_model()\n",
    "\n",
    "\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        frame = img.copy()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if useBoth or useDlib:\n",
    "            show_stats = True\n",
    "            draw_contours = True\n",
    "            if useBoth:\n",
    "                show_stats = False\n",
    "                draw_contours = False\n",
    "\n",
    "            final, faces = dlibDetection(frame, detector, predictor, show_stats, draw_contours)\n",
    "\n",
    "        if useBoth or useCascade:\n",
    "            final, eye, smile = haarDetection(face_cascade, eye_cascade, smile_cascade, gray, img)\n",
    "\n",
    "\n",
    "\n",
    "        takeSelfies(frame, gray, output_folder, cartoon, pencil, useCascade, useDlib, useBoth, eye, smile, faces)\n",
    "\n",
    "        cv2.imshow('Video', final)\n",
    "\n",
    "        key2 = cv2.waitKey(1) & 0xFF\n",
    "        if key2 == ord('q'):\n",
    "            break\n",
    "        if key2 == ord('p'):\n",
    "            pencil = True\n",
    "            cartoon = False\n",
    "            print(\"taking *PENCIL* selfies..\")\n",
    "        if key2 == ord('c'):\n",
    "            pencil = False\n",
    "            cartoon = True\n",
    "            print(\"taking *CARTOON* selfies..\")\n",
    "\n",
    "        if key2 == ord('n'):\n",
    "            print(\"taking *REGULAR* selfies \")\n",
    "            pencil = False\n",
    "            cartoon = False\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_taken_selfie = None\n",
    "total = 0\n",
    "counter = 0\n",
    "\n",
    "useCascade = True\n",
    "useDlib = True\n",
    "useBoth = False\n",
    "\n",
    "if useDlib and useCascade:\n",
    "    useBoth = True\n",
    "    useCascade = False\n",
    "    useDlib = False\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')## Variables and Globals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for regular selfies press 'n'\n",
      "for cartoon selfies press 'c'\n",
      "for pencil selfies press 'p'\n",
      "\n",
      "starting looking for perfect selfie mode\n",
      "Initializing model\n",
      "selfies_2021_05_31_01_10_12\\selfie_frame_0.png written!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "compare_sim() got an unexpected keyword argument 'full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-14380d3ae067>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0museCascade\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0museDlib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0museBoth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meye_cascade\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmile_cascade\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcartoon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpencil\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-1775efe9dc8e>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(useCascade, useDlib, useBoth, face_cascade, eye_cascade, smile_cascade, cartoon, pencil)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mtakeSelfies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcartoon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpencil\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0museCascade\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0museDlib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0museBoth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meye\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Video'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-6f7da9bb1642>\u001b[0m in \u001b[0;36mtakeSelfies\u001b[1;34m(frame, gray, output_folder, cartoon, pencil, useCascade, useDlib, useBoth, eyes_cascade, smile_cascade, faces)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# we need to check it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlast_taken_selfie\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare_sim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_taken_selfie\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                 \u001b[1;31m# print(\"SSIM: {}\".format(score))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[1;31m# check if there is a difference between current img to last taken selfie.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: compare_sim() got an unexpected keyword argument 'full'"
     ]
    }
   ],
   "source": [
    "run(useCascade, useDlib, useBoth, face_cascade, eye_cascade, smile_cascade, cartoon=False, pencil=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
